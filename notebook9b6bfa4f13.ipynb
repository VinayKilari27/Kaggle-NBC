{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# step1:Load and Prepare the Data\nimport csv\nimport random\nfrom collections import defaultdict, Counter\n\n# Function to load data from a CSV file\ndef load_data(filename):\n    with open(filename, 'r', encoding='utf-8') as file:\n        reader = csv.reader(file)\n        headers = next(reader)\n        data = [row for row in reader]\n    return headers, data\n\n# Load training data\ntrain_headers, train_data = load_data('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-25T20:24:44.030601Z","iopub.execute_input":"2023-11-25T20:24:44.030954Z","iopub.status.idle":"2023-11-25T20:24:44.115834Z","shell.execute_reply.started":"2023-11-25T20:24:44.030918Z","shell.execute_reply":"2023-11-25T20:24:44.115099Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Step 2: Preprocess the Text Data\nimport re\nimport string\n\n# Function to clean and tokenize text\ndef preprocess_text(text):\n    text = text.lower()\n    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text)\n    return text.split()\n\n# Preprocess essays in the training data\nfor row in train_data:\n    text_index = train_headers.index('text')\n    row[text_index] = preprocess_text(row[text_index])","metadata":{"execution":{"iopub.status.busy":"2023-11-25T20:24:44.117835Z","iopub.execute_input":"2023-11-25T20:24:44.118189Z","iopub.status.idle":"2023-11-25T20:24:44.302736Z","shell.execute_reply.started":"2023-11-25T20:24:44.118156Z","shell.execute_reply":"2023-11-25T20:24:44.301729Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Step 3: Split the Data into Training and Development Sets bold text\n# Split the data manually\ndef split_data(data, split_ratio=0.8):\n    random.shuffle(data)\n    split_point = int(len(data) * split_ratio)\n    return data[:split_point], data[split_point:]\n\ntrain_data, dev_data = split_data(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T20:24:44.304204Z","iopub.execute_input":"2023-11-25T20:24:44.304559Z","iopub.status.idle":"2023-11-25T20:24:44.312107Z","shell.execute_reply.started":"2023-11-25T20:24:44.304526Z","shell.execute_reply":"2023-11-25T20:24:44.311170Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Step 4: Build the Vocabulary and the Reverse Index\n# Function to build vocabulary and reverse index\ndef build_vocabulary_and_index(data):\n    word_counts = Counter(word for row in data for word in row[train_headers.index('text')])\n    vocabulary = {word for word, count in word_counts.items() if count >= 5}\n    reverse_index = {word: idx for idx, word in enumerate(vocabulary)}\n    return vocabulary, reverse_index\n\nvocabulary, reverse_index = build_vocabulary_and_index(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T20:24:44.313285Z","iopub.execute_input":"2023-11-25T20:24:44.313625Z","iopub.status.idle":"2023-11-25T20:24:44.440171Z","shell.execute_reply.started":"2023-11-25T20:24:44.313591Z","shell.execute_reply":"2023-11-25T20:24:44.439147Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Step 5: Calculate Probabilities\n# Function to calculate word occurrence probabilities\ndef calculate_probabilities(data, vocabulary):\n    word_occurrences = defaultdict(int)\n    class_word_occurrences = defaultdict(lambda: defaultdict(int))\n    class_counts = defaultdict(int)\n    \n    for row in data:\n        label = int(row[train_headers.index('generated')])\n        class_counts[label] += 1\n        words = set(row[train_headers.index('text')])\n        for word in words:\n            if word in vocabulary:\n                word_occurrences[word] += 1\n                class_word_occurrences[label][word] += 1\n\n    total_docs = len(data)\n    word_probs = {word: count / total_docs for word, count in word_occurrences.items()}\n    word_given_class_probs = {\n        label: {word: (count / class_counts[label]) for word, count in word_counts.items()}\n        for label, word_counts in class_word_occurrences.items()\n    }\n    \n    return word_probs, word_given_class_probs\n\nword_probs, word_given_class_probs = calculate_probabilities(train_data, vocabulary)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T20:24:44.441420Z","iopub.execute_input":"2023-11-25T20:24:44.441757Z","iopub.status.idle":"2023-11-25T20:24:44.592195Z","shell.execute_reply.started":"2023-11-25T20:24:44.441726Z","shell.execute_reply":"2023-11-25T20:24:44.591233Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Step 6: Define the Classifier and Evaluate Accuracy\n# Function to classify a new document\ndef classify(document, vocabulary, reverse_index, word_given_class_probs):\n    doc_words = set(document)\n    class_scores = defaultdict(float)\n    \n    for word in doc_words:\n        if word in vocabulary:\n            for class_label, probs in word_given_class_probs.items():\n                word_idx = reverse_index[word]\n                class_scores[class_label] += probs.get(word_idx, 0)\n    \n    return max(class_scores, key=class_scores.get)\n\n# Function to evaluate the classifier\ndef evaluate(data, classify_func):\n    correct = 0\n    for row in data:\n        label = int(row[train_headers.index('generated')])\n        prediction = classify_func(row[train_headers.index('text')], vocabulary, reverse_index, word_given_class_probs)\n        if prediction == label:\n            correct += 1\n    return correct / len(data)\n\naccuracy = evaluate(dev_data, classify)\nprint(f\"Development Set Accuracy: {accuracy:.2%}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T20:24:44.594713Z","iopub.execute_input":"2023-11-25T20:24:44.595637Z","iopub.status.idle":"2023-11-25T20:24:44.692843Z","shell.execute_reply.started":"2023-11-25T20:24:44.595599Z","shell.execute_reply":"2023-11-25T20:24:44.691950Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Development Set Accuracy: 99.64%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 7: Experiment with Smoothing and Identify Top Predictive Words\ndef train_naive_bayes(data, vocabulary):\n    word_given_class_counts = defaultdict(lambda: defaultdict(int))\n    class_counts = defaultdict(int)\n    \n    # Count how many times each word appears in documents of each class\n    for row in data:\n        label = int(row[train_headers.index('generated')])\n        class_counts[label] += 1\n        words = row[train_headers.index('text')]\n        for word in words:\n            if word in vocabulary:\n                word_given_class_counts[label][word] += 1\n    \n    # Apply Laplace smoothing to word counts and convert them to probabilities\n    word_given_class_probs = {\n        label: {\n            word: (word_count + 1) / (sum(class_word_counts.values()) + len(vocabulary))\n            for word, word_count in class_word_counts.items()\n        } for label, class_word_counts in word_given_class_counts.items()\n    }\n    \n    # Calculate class probabilities\n    total_docs = sum(class_counts.values())\n    class_probs = {label: count / total_docs for label, count in class_counts.items()}\n    \n    return word_given_class_probs, class_probs\n\n# Run the training function\nword_given_class_probs, class_probs = train_naive_bayes(train_data, vocabulary)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T20:24:44.694322Z","iopub.execute_input":"2023-11-25T20:24:44.694648Z","iopub.status.idle":"2023-11-25T20:24:45.082745Z","shell.execute_reply.started":"2023-11-25T20:24:44.694621Z","shell.execute_reply":"2023-11-25T20:24:45.081719Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Step 8: Prepare Submission\ndef smooth_and_top_words(word_given_class_probs, vocabulary, smooth_factor=1):\n    smoothed_probs = {}\n    top_words_probs = {}  # Change the name of this variable to match what you return\n\n    # Apply smoothing and calculate probabilities\n    for label, word_probs in word_given_class_probs.items():\n        total_words = sum(word_probs.values()) + smooth_factor * len(vocabulary)\n        smoothed_probs[label] = {\n            word: (count + smooth_factor) / total_words\n            for word, count in word_probs.items()\n        }\n        # Get the top 10 words by probability\n        top_words_probs[label] = sorted(smoothed_probs[label].items(), key=lambda item: item[1], reverse=True)[:10]\n\n    return top_words_probs\n\ntop_words_probs = smooth_and_top_words(word_given_class_probs, vocabulary)\n\n# Print top words\nfor label, words in top_words_probs.items():  # Use top_words_probs here\n    print(f\"Class {label}:\")\n    for word, prob in words:\n        print(f\"  {word}: {prob:.6f}\")\n\n# Function to save top words to a CSV file\ndef save_top_words_to_csv(top_words_probs, filename):\n    with open(filename, 'w', newline='', encoding='utf-8') as file:\n        writer = csv.writer(file)\n        writer.writerow([\"Class\", \"Word\", \"Probability\"])\n        for label, words in top_words_probs.items():\n            for word, prob in words:\n                writer.writerow([label, word, prob])\n\n# Call the function to save the data\nsave_top_words_to_csv(top_words_probs, 'submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-25T20:24:45.083933Z","iopub.execute_input":"2023-11-25T20:24:45.084204Z","iopub.status.idle":"2023-11-25T20:24:45.100189Z","shell.execute_reply.started":"2023-11-25T20:24:45.084180Z","shell.execute_reply":"2023-11-25T20:24:45.099330Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Class 0:\n  the: 0.000261\n  to: 0.000253\n  of: 0.000253\n  a: 0.000251\n  and: 0.000251\n  in: 0.000251\n  is: 0.000249\n  that: 0.000249\n  for: 0.000248\n  it: 0.000248\nClass 1:\n  the: 0.000247\n  for: 0.000246\n  to: 0.000246\n  of: 0.000246\n  and: 0.000246\n  a: 0.000246\n  states: 0.000246\n  is: 0.000246\n  that: 0.000246\n  more: 0.000246\n","output_type":"stream"}]}]}